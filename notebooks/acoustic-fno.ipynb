{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837de934",
   "metadata": {},
   "source": [
    "# Baseline with Neural Operator Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from neuralop.models import FNO\n",
    "from neuralop.training import AdamW\n",
    "from neuralop import LpLoss, H1Loss\n",
    "from neuralop.training.incremental import IncrementalFNOTrainer\n",
    "from neuralop.data.transforms.data_processors import IncrementalDataProcessor\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import HTML\n",
    "\n",
    "from acoustic_no.data import AcousticDataset, ShuffledAcousticDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a239dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891e7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = ShuffledAcousticDataset(\n",
    "    dataset_dir=pathlib.Path(\"/opt/dlami/nvme/acoustic-no/training/processed\"),\n",
    ")\n",
    "print(f\"Dataset size: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4978466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample from the dataset\n",
    "data = dataset[0]\n",
    "p = data[\"y\"]\n",
    "v = data[\"v\"]\n",
    "a = data[\"a\"]\n",
    "# Move velocity x and y to r and g channels\n",
    "v = v.reshape(-1, 2, v.shape[1], v.shape[2])\n",
    "v = v.permute(0, 2, 3, 1)\n",
    "# Extend the velocity to 3 channels\n",
    "v = torch.cat([v, torch.zeros_like(v[:, :, :, 0:1])], dim=3)\n",
    "# Normalize the velocity\n",
    "v = (v - v.min()) / (v.max() - v.min())\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(p[0, :, :], interpolation=\"nearest\")\n",
    "ax[0].set_title(\"Pressure\")\n",
    "ax[1].imshow(v[0, :, :], interpolation=\"nearest\")\n",
    "ax[1].set_title(\"Velocity\")\n",
    "ax[2].imshow(a[0, :, :], interpolation=\"nearest\")\n",
    "ax[2].set_title(\"Alpha\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f55745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset = Subset(dataset, range(train_size))\n",
    "val_dataset = Subset(dataset, range(train_size, len(dataset)))\n",
    "# Use a random subset of the dataset for training\n",
    "N_TRAIN, N_VAL = 1024, 16\n",
    "train_dataset = Subset(train_dataset, range(N_TRAIN))\n",
    "val_dataset = Subset(val_dataset, range(N_VAL))\n",
    "# Create a data loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=10,\n",
    ")\n",
    "val_loader = {\n",
    "    \"64x64\": torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=10,\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609e7ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = dataset.depth\n",
    "depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a6be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNO(\n",
    "    n_modes=(16, 16),\n",
    "    in_channels=depth * 3 + 1,\n",
    "    out_channels=depth,\n",
    "    n_layers=8,\n",
    "    hidden_channels=128,\n",
    "    projection_channel_ratio=2,\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                                lr=8e-3,\n",
    "                                weight_decay=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2aabb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = IncrementalDataProcessor(\n",
    "    in_normalizer=None,\n",
    "    out_normalizer=None,\n",
    "    device=device,\n",
    "    subsampling_rates=[8, 4, 2, 1],\n",
    "    dataset_resolution=64,\n",
    "    dataset_indices=[2, 3],\n",
    "    epoch_gap=1,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "data_transform = data_transform.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b774e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2loss = LpLoss(d=2, p=2)\n",
    "h1loss = H1Loss(d=2)\n",
    "train_loss = h1loss\n",
    "eval_losses = {\"h1\": h1loss, \"l2\": l2loss}\n",
    "\n",
    "# Finally pass all of these to the Trainer\n",
    "trainer = IncrementalFNOTrainer(\n",
    "    model=model,\n",
    "    n_epochs=4,\n",
    "    data_processor=data_transform,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    "    incremental_loss_gap=False,\n",
    "    incremental_grad=True,\n",
    "    incremental_grad_eps=0.9999,\n",
    "    incremental_loss_eps = 0.001,\n",
    "    incremental_buffer=5,\n",
    "    incremental_max_iter=1,\n",
    "    incremental_grad_max_iter=2,\n",
    ")\n",
    "\n",
    "trainer.train(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    regularizer=False,\n",
    "    training_loss=train_loss,\n",
    "    eval_losses=eval_losses,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e3c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "model.eval()\n",
    "eval_data = val_dataset[1]\n",
    "x = eval_data[\"x\"]\n",
    "p = eval_data[\"y\"]\n",
    "v = eval_data[\"v\"]\n",
    "a = eval_data[\"a\"]\n",
    "with torch.no_grad():\n",
    "    pred = model(x.unsqueeze(0).to(device))\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "ax[0].imshow(pred[0, -1].cpu().numpy(), cmap='viridis', vmin=-10, vmax=10)\n",
    "ax[0].set_title(\"Predicted Pressure\")\n",
    "ax[1].imshow(p[-1].cpu().numpy(), cmap='viridis', vmin=-10, vmax=10)\n",
    "ax[1].set_title(\"Ground Truth Pressure\")\n",
    "ax[2].imshow(pred[0, -1].cpu().numpy() - p[-1].cpu().numpy(), cmap='viridis', vmin=-10, vmax=10)\n",
    "ax[2].set_title(\"Difference\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e976ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tqdm progress bar for the simulation\n",
    "pbar = tqdm(total=depth, desc=\"Animation Progress\", unit=\"step\")\n",
    "\n",
    "# Generate the animation for the pressure field.\n",
    "def update(frame):\n",
    "    ax.clear()\n",
    "    im = ax.imshow(\n",
    "        p.cpu()[frame].T,\n",
    "        interpolation='nearest',\n",
    "        vmin=-10.0,\n",
    "        vmax=10.0\n",
    "    )\n",
    "    ax.set_title(f'Pressure field at step {frame}')\n",
    "    ax.axis('off')\n",
    "    # Update the progress bar\n",
    "    pbar.update(1)\n",
    "    # Close the progress bar when done\n",
    "    if frame == depth - 1:\n",
    "        pbar.close()\n",
    "    return [im]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Wrap the animation generation with tqdm for progress tracking\n",
    "ani = FuncAnimation(\n",
    "    fig,\n",
    "    update,\n",
    "    frames=range(depth),\n",
    "    interval=1000 / 60,\n",
    "    blit=False,\n",
    "    repeat=True,\n",
    ")\n",
    "\n",
    "# Save gif\n",
    "ani.save(\"pressure_field.gif\", fps=60, writer='imagemagick')\n",
    "# Display the animation in the notebook\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe10ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tqdm progress bar for the simulation\n",
    "pbar = tqdm(total=depth, desc=\"Animation Progress\", unit=\"step\")\n",
    "\n",
    "# Generate the animation for the pressure field.\n",
    "def update(frame):\n",
    "    ax.clear()\n",
    "    im = ax.imshow(\n",
    "        pred.cpu()[0, frame].T,\n",
    "        interpolation='nearest',\n",
    "        vmin=-10.0,\n",
    "        vmax=10.0\n",
    "    )\n",
    "    ax.set_title(f'Pressure field at step {frame}')\n",
    "    ax.axis('off')\n",
    "    # Update the progress bar\n",
    "    pbar.update(1)\n",
    "    # Close the progress bar when done\n",
    "    if frame == depth - 1:\n",
    "        pbar.close()\n",
    "    return [im]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Wrap the animation generation with tqdm for progress tracking\n",
    "ani = FuncAnimation(\n",
    "    fig,\n",
    "    update,\n",
    "    frames=range(depth),\n",
    "    interval=1000 / 60,\n",
    "    blit=False,\n",
    "    repeat=True,\n",
    ")\n",
    "\n",
    "# Save gif\n",
    "ani.save(\"pred_pressure_field.gif\", fps=60, writer='imagemagick')\n",
    "# Display the animation in the notebook\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f689fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark the model performance on the validation set with MSE loss.\n",
    "model.eval()\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "val_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for data in val_loader[\"64x64\"]:\n",
    "        x = data[\"x\"].to(device)\n",
    "        y = data[\"y\"].to(device)\n",
    "        pred = model(x)\n",
    "        loss = mse_loss(pred, y)\n",
    "        val_loss += loss.item()\n",
    "val_loss /= len(val_loader[\"64x64\"])\n",
    "print(f\"Validation loss: {val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
